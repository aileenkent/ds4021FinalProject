{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f484e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b1959b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data, test data\n",
    "X_train = pd.read_csv(\"../Data/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../Data/y_train.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"../Data/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../Data/y_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e151ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing (drop id, one hot encode)\n",
    "\n",
    "X_train = X_train.drop(columns=[\"User_ID\"])\n",
    "X_test = X_test.drop(columns=[\"User_ID\"])\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=[\"Gender\", \"Social_Media_Platform\"], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=[\"Gender\", \"Social_Media_Platform\"], drop_first=True)\n",
    "\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.values.flatten()\n",
    "y_test = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844848c",
   "metadata": {},
   "source": [
    "# Neural Network Best Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ac25ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef62508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert best params\n",
    "\n",
    "best_params = pd.read_csv(\"./best_params/best_nn_params.csv\")\n",
    "\n",
    "best_hidden = int(best_params[\"hidden_dim\"])\n",
    "best_lr = float(best_params[\"lr\"])\n",
    "best_batch = int(best_params[\"batch_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e01ff042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain best model on training set\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1,1)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    batch_size=best_batch,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model = NeuralNet(input_dim=input_dim, hidden_dim=best_hidden)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=best_lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):  # same number of epochs used in training\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58e2b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Set Performance:\n",
      "   MSE: 0.9281\n",
      "   R²:  0.5413\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on the test set\n",
    "\n",
    "model.eval()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Final Test Set Performance:\")\n",
    "print(f\"   MSE: {mse:.4f}\")\n",
    "print(f\"   R²:  {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffbbdb",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7da1d323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load best parameters\\nbest_params_svm = pd.read_csv(\"./best_params/best_svm_params.csv\")\\n\\n# extract best parameters\\nbest_C = float(best_params_svm[\"C\"])\\nbest_gamma = float(best_params_svm[\"gamma\"])\\nbest_kernel = best_params_svm[\"kernel\"].iloc[0]\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# load best parameters\n",
    "best_params_svm = pd.read_csv(\"./best_params/best_svm_params.csv\")\n",
    "\n",
    "# extract best parameters\n",
    "best_C = float(best_params_svm[\"C\"])\n",
    "best_gamma = float(best_params_svm[\"gamma\"])\n",
    "best_kernel = best_params_svm[\"kernel\"].iloc[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c4e11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter in best params Best parameters: {'C': 0.1, 'kernel': 'linear'}\n",
    "best_C = 0.1\n",
    "best_gamma = 'kernel'\n",
    "best_kernel = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62cc8843",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SVR.__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# retrain best model on full training set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m svm_model = \u001b[43mSVR\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_C\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1234\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m svm_model.fit(X_train_scaled, y_train)\n",
      "\u001b[31mTypeError\u001b[39m: SVR.__init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "# retrain best model on full training set\n",
    "svm_model = SVR(\n",
    "    C=best_C,\n",
    "    gamma=best_gamma,\n",
    "    kernel=best_kernel,\n",
    "    random_state=1234\n",
    ")\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Support Vector Machine (SVM) - Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Parameters: C={best_C}, gamma={best_gamma}, kernel='{best_kernel}'\")\n",
    "print(f\"   MSE: {mse_svm:.4f}\")\n",
    "print(f\"   R²:  {r2_svm:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f72b8",
   "metadata": {},
   "source": [
    "# ElasticNet Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d650b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# load best parameters\n",
    "best_params_enet = pd.read_csv(\"./best_params/best_elasticnet_params.csv\")\n",
    "\n",
    "# extract best parameters\n",
    "best_alpha = float(best_params_enet[\"alpha\"])\n",
    "best_l1_ratio = float(best_params_enet[\"l1_ratio\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb93414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually input best params\n",
    "\n",
    "best_alpha = 0.01\n",
    "best_l1_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain best model on full training set\n",
    "enet_model = ElasticNet(\n",
    "    alpha=best_alpha,\n",
    "    l1_ratio=best_l1_ratio,\n",
    "    random_state=1234,\n",
    "    max_iter=10000  # increased for convergence\n",
    ")\n",
    "enet_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc32d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "y_pred_enet = enet_model.predict(X_test_scaled)\n",
    "\n",
    "mse_enet = mean_squared_error(y_test, y_pred_enet)\n",
    "r2_enet = r2_score(y_test, y_pred_enet)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ElasticNet Regression - Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Parameters: alpha={best_alpha}, l1_ratio={best_l1_ratio}\")\n",
    "print(f\"   MSE: {mse_enet:.4f}\")\n",
    "print(f\"   R²:  {r2_enet:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f215a5",
   "metadata": {},
   "source": [
    "# Ensemble Methods Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Random Forest typically doesn't require feature scaling\n",
    "#X_train_final = X_train_processed.values\n",
    "#X_test_final = X_test_processed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# load best parameters\n",
    "best_params_rf = pd.read_csv(\"./best_params/best_rf_params.csv\")\n",
    "\n",
    "# extract best parameters\n",
    "best_n_estimators = int(best_params_rf[\"n_estimators\"])\n",
    "best_max_depth = int(best_params_rf[\"max_depth\"]) if pd.notna(best_params_rf[\"max_depth\"].iloc[0]) else None\n",
    "best_min_samples_split = int(best_params_rf[\"min_samples_split\"])\n",
    "best_min_samples_leaf = int(best_params_rf[\"min_samples_leaf\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest best params: Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "best_n_estimators = 200\n",
    "best_max_depth = 10\n",
    "best_min_samples_split = 5\n",
    "best_min_samples_leaf = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6bfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain best model on full training set\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=best_n_estimators,\n",
    "    max_depth=best_max_depth,\n",
    "    min_samples_split=best_min_samples_split,\n",
    "    min_samples_leaf=best_min_samples_leaf,\n",
    "    random_state=1234,\n",
    "    n_jobs=-1  # use all available cores\n",
    ")\n",
    "rf_model.fit(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a244b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "y_pred_rf = rf_model.predict(X_test_final)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Random Forest (Ensemble) - Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Parameters: n_estimators={best_n_estimators}, max_depth={best_max_depth}\")\n",
    "print(f\"                min_samples_split={best_min_samples_split}, min_samples_leaf={best_min_samples_leaf}\")\n",
    "print(f\"   MSE: {mse_rf:.4f}\")\n",
    "print(f\"   R²:  {r2_rf:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
